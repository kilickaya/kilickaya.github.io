---
layout: default
title: Mert Kilickaya
---
<div class="blurb">
	
	<div class="toright">
            <a href="https://twitter.com/mertkilickaya_"> <img border="0" alt="twitter" src="https://upload.wikimedia.org/wikipedia/sco/thumb/9/9f/Twitter_bird_logo_2012.svg/2534px-Twitter_bird_logo_2012.svg.png" width="40" height="40"> </a>
            <a href="https://scholar.google.nl/citations?user=50ZzaacAAAAJ&hl=en&oi=ao"> <img border="0" alt="scholar" src="http://www.public.asu.edu/~mdedeogl/images/gscholar.png" width="40" height="40"> </a>
	</div>
	
	<div>
	
	<h1>Hello world, I'm Mert Kilickaya!</h1>
	<p>I'm a third year PhD. researcher at <a href="https://ivi.fnwi.uva.nl/quva/">QUvA</a> Lab, The University of Amsterdam (UvA). QUvA Lab is a collaborative effort between Qualcomm and UvA, which is directed by <a href="https://staff.fnwi.uva.nl/m.welling/">Max Welling</a>, <a href="https://staff.fnwi.uva.nl/a.w.m.smeulders/">Arnold Smeulders</a> and <a href="http://www.ceessnoek.info/">Cees Snoek</a>. My research interest is at the intersection of vision and language. Specifically, I am interested in developing visual representations that can be utilized for image captioning, visual question answering and visual dialogue systems. If interested, please find my MSc. thesis <a href="https://www.dropbox.com/s/gmk6m51w5wgfk4w/main.pdf?dl=0">here</a> and my Curriculum Vitae <a href="https://www.dropbox.com/s/tki5ah9z7gx0vbl/CV%20M.%20Kilickaya.pdf?dl=0">here</a>. </a></p>

	</div>

        <h2> Contact </h2>

</div><!-- /.blurb -->
