<!DOCTYPE HTML>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Mert Kilickaya</title>
  <link rel="stylesheet" href="stylesheet.css">
  <link rel="icon" type="image/jpg" href="images/avatar3.JPG">
  <style>
    /* Basic styles for modernization */
    body {
      font-family: Arial, sans-serif;
      line-height: 1.6;
      margin: 0;
      padding: 0;
      background-color: #f9f9f9;
      color: #333;
    }
    header {
      background: #fff;
      padding: 10px 20px;
      border-bottom: 1px solid #ddd;
      display: flex;
      align-items: center;
      justify-content: space-between;
    }
    header .logo {
      display: flex;
      align-items: center;
    }
    header .logo img {
      border-radius: 50%;
      width: 50px;
      height: 50px;
      margin-right: 10px;
    }
    header nav {
      display: flex;
      gap: 15px;
    }
    header nav a {
      text-decoration: none;
      color: #333;
      font-weight: bold;
    }
    .hero {
      text-align: center;
      padding: 40px 20px;
      background-color: #f3f3f3;
    }
    .bio {
      display: flex;
      align-items: center;
      max-width: 900px;
      margin: 20px auto;
      padding: 20px;
      background: #fff;
      border-radius: 8px;
      box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
    }
    .bio img {
      border-radius: 50%;
      margin-right: 20px;
      max-width: 150px;
    }
    .bio p {
      margin: 5px 0;
    }
    .news {
      max-width: 900px;
      margin: 20px auto;
      padding: 20px;
      background: #fff;
      border-radius: 8px;
      box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
    }
    .news h2 {
      margin-top: 0;
    }
    .news ul {
      list-style: none;
      padding: 0;
    }
    .news li {
      display: flex;
      align-items: flex-start;
      margin-bottom: 15px;
    }
    .news li span {
      font-weight: bold;
      margin-right: 15px;
      flex-shrink: 0;
    }
    .news li a {
      color: #0066cc;
      text-decoration: none;
    }
  </style>
</head>
<body>

  <!--
<header>
  <div class="logo">
    <img src="images/avatar3.JPG" alt="Profile Picture">
    <span>Mert Kilickaya</span>
  </div>
  
  <nav>
    <a href="#bio">Bio</a>
    <a href="#news">News</a>
    <a href="#experience">Experience</a>
    <a href="#research">Research</a>
    <a href="#patents">Patents</a>
    <a href="#supervision">Supervision</a>
  </nav>
 
</header>
 -->
<section id="bio" class="bio">
  <img src="images/avatar3.JPG" alt="Mert Kilickaya">
  <div>
    <p>
      Hello! I am an AI researcher. I focus on deep learning of self-supervised representations. My goal is to develop autonomous visual learners that can continuously improve by extracting their own supervision from dynamic visual data streams.</p>
                  <p>    
                  Towards that goal, I have worked at the <a href="https://dai.win.tue.nl/team/5/" target="_blank"> Learning to Learn Lab</a>, where I advanced techniques in self-supervised continual learning, enabling AI systems to autonomously adapt and improve without relying on external annotations. 
                      Before that, I obtained my PhD at the <a href="https://ivi.fnwi.uva.nl/quva/" target="_blank"> QUvA Lab </a>, on deep vision under the guidance of <a href="https://scholar.google.com/citations?user=aa5Ou7gAAAAJ&hl=en" target="_blank"> Arnold Smeulders</a>.
                  </p>    <p>
      <a href="mailto:kilickayamert@gmail.com">Email</a> | 
      <a href="resume/resume.pdf" target="_blank">CV</a> | 
      <a href="https://scholar.google.com/citations?user=MBMjO0sAAAAJ&hl=en&oi=ao" target="_blank">Google Scholar</a> | 
      <a href="https://www.linkedin.com/in/mert-kilickaya/" target="_blank">LinkedIn</a>
    </p>
  </div>
</section>

<section id="news" class="news">
  <h2>News</h2>
  <ul>
    <li>
      <span>10/2024</span>
      <a href="resume/eccv_reviewer.pdf" target="_blank">Honored to be an outstanding reviewer for ECCV'24!</a>
    </li>
    <li>
      <span>07/2024</span>
      <a href="https://arxiv.org/pdf/2407.16269" target="_blank">Our work on Transformer Architecture Search is accepted at ECCV'24!</a>
    </li>
    <li>
      <span>09/2023</span>
      <a href="https://arxiv.org/pdf/2309.01561.pdf" target="_blank">Our work on Locality-aware Vision-Transformer is accepted at BMVC'23!</a>
    </li>
    <!--
    <li>
      <span>04/2023</span>
      <a href="https://arxiv.org/pdf/2301.11417.pdf" target="_blank">Our work on self-incremental learning is accepted at CVPR Workshop!</a>
    </li>
    <li>
      <span>02/2023</span>
      <a href="https://arxiv.org/pdf/2302.00353.pdf" target="_blank">Our survey on label-efficient incremental learning is now online.</a>
    </li>
    <li>
      <span>11/2022</span>
      <a href="resume/thesis.pdf" target="_blank">I completed my PhD!</a>
    </li>
    -->
  </ul>
</section>

</body>
</html>

<style>
  .experience-section {
    background-color: #f9f9f9;
    padding: 40px 20px;
    margin: 0 auto;
    max-width: 900px;
    border-radius: 8px;
    box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
  }

  .experience-section h2 {
    text-align: center;
    margin-bottom: 30px;
    font-size: 1.8rem;
    color: #333;
  }

  .experience-card {
    display: flex;
    align-items: center;
    background: #fff;
    margin-bottom: 20px;
    padding: 15px;
    border-radius: 8px;
    box-shadow: 0 1px 3px rgba(0, 0, 0, 0.1);
  }

  .experience-card img {
    width: 100px;
    height: auto;
    border-radius: 8px;
    margin-right: 20px;
  }

  .experience-details {
    flex: 1;
  }

  .experience-details .paper-title {
    font-size: 1.2rem;
    font-weight: bold;
    margin-bottom: 5px;
    color: #0066cc;
  }

  .experience-details .date {
    font-size: 1rem;
    font-weight: bold;
    color: #555;
    margin-bottom: 5px;
  }

  .experience-details .position {
    font-size: 1rem;
    color: #333;
  }

  @media (max-width: 600px) {
    .experience-card {
      flex-direction: column;
      align-items: flex-start;
    }

    .experience-card img {
      margin-bottom: 10px;
    }
  }
</style>

<section id="experience" class="experience-section">
  <h2>Experience</h2>
  <div class="experience-card">
    <img src="images/TUE.png" alt="TU Eindhoven">
    <div class="experience-details">
      <div class="paper-title">Learning to Learn Lab, Eindhoven University of Technology, Netherlands</div>
      <div class="date">2022-2023</div>
      <p class="position">ML Researcher</p>
    </div>
  </div>

  <div class="experience-card">
    <img src="images/QUVA.png" alt="QUvA Deep Vision Lab">
    <div class="experience-details">
      <div class="paper-title">QUvA Deep Vision Lab, University of Amsterdam, Netherlands</div>
      <div class="date">2017-2022</div>
      <p class="position">PhD Researcher</p>
    </div>
  </div>

  <div class="experience-card">
    <img src="images/Huawei.jpg" alt="Huawei Visual Search Lab">
    <div class="experience-details">
      <div class="paper-title">Huawei Visual Search Lab, Helsinki, Finland</div>
      <div class="date">2021 March - 2022 January</div>
      <p class="position">Research Scientist Intern</p>
    </div>
  </div>
</section>


<style>
  .research-section {
    background-color: #f9f9f9;
    padding: 40px 20px;
    margin: 0 auto;
    max-width: 1200px;
    border-radius: 8px;
    box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
  }

  .research-section h2 {
    text-align: center;
    margin-bottom: 30px;
    font-size: 1.8rem;
    color: #333;
  }

  .research-card {
    display: flex;
    flex-wrap: wrap;
    align-items: flex-start;
    background: #fff;
    margin-bottom: 20px;
    padding: 20px;
    border-radius: 8px;
    box-shadow: 0 1px 3px rgba(0, 0, 0, 0.1);
  }

  .research-card img {
    width: 150px;
    height: auto;
    border-radius: 8px;
    margin-right: 20px;
  }

  .research-details {
    flex: 1;
  }

  .research-details .title {
    font-size: 1.2rem;
    font-weight: bold;
    color: #0066cc;
    margin-bottom: 5px;
  }

  .research-details .authors {
    font-size: 1rem;
    color: #555;
    margin-bottom: 5px;
  }

  .research-details .conference {
    font-size: 1rem;
    font-weight: bold;
    color: #333;
    margin-bottom: 10px;
  }

  .research-details .links a {
    color: #0066cc;
    text-decoration: none;
    margin-right: 10px;
    font-size: 0.9rem;
  }

  .research-details p {
    margin-top: 10px;
    font-size: 0.9rem;
    color: #333;
  }

  @media (max-width: 600px) {
    .research-card {
      flex-direction: column;
      align-items: flex-start;
    }

    .research-card img {
      margin-bottom: 10px;
    }
  }
</style>

<section  id="research" class="research-section">
  <h2>Research</h2>

  <div class="research-card">
    <img src="images/hytas.png" alt="HyTAS">
    <div class="research-details">
      <div class="title">HyTAS: A Hyperspectral Image Transformer Architecture Search Benchmark and Analysis</div>
      <div class="authors">
        <a href="https://dblp.org/pid/280/1516.html" target="_blank">Fangqin Zhou</a>, 
        <a href="https://scholar.google.com/citations?user=MBMjO0sAAAAJ&hl=en&oi=ao" target="_blank">Mert Kilickaya</a>, 
        <a href="https://scholar.google.com/citations?user=HhDsD9UAAAAJ&hl=en" target="_blank">Joaquin Vanschoren</a>, 
        <a href="XXX" target="_blank">Ran Piao</a>
      </div>
      <div class="conference">ECCV 2024</div>
      <div class="links">
        <a href="https://arxiv.org/pdf/2407.16269" target="_blank">arXiv</a>
        <a href="https://github.com/zhoufangqin/HyTAS/tree/main" target="_blank">GitHub</a>
      </div>
      <p>We present HyTAS, a quick method for hyperspectral vision transformer architecture search.</p>
    </div>
  </div>

  <div class="research-card">
    <img src="images/hylite.PNG" alt="HyLITE">
    <div class="research-details">
      <div class="title">Locality-Aware Hyperspectral Classification</div>
      <div class="authors">
        <a href="https://dblp.org/pid/280/1516.html" target="_blank">Fangqin Zhou</a>, 
        <a href="https://scholar.google.com/citations?user=MBMjO0sAAAAJ&hl=en&oi=ao" target="_blank">Mert Kilickaya</a>, 
        <a href="https://scholar.google.com/citations?user=HhDsD9UAAAAJ&hl=en" target="_blank">Joaquin Vanschoren</a>
      </div>
      <div class="conference">BMVC 2023</div>
      <div class="links">
        <a href="https://arxiv.org/pdf/2309.01561.pdf" target="_blank">arXiv</a>
        <a href="https://github.com/zhoufangqin/HyLITE" target="_blank">GitHub</a>
      </div>
      <p>We propose HyLITE, a vision-transformer for hyperspectral image classification.</p>
    </div>
  </div>

  <div class="research-card">
    <img src="images/survey_cil.PNG" alt="Towards Label-Efficient Incremental Learning: A Survey">
    <div class="research-details">
      <div class="title">Towards Label-Efficient Incremental Learning: A Survey</div>
      <div class="authors">
        <a href="https://scholar.google.com/citations?user=MBMjO0sAAAAJ&hl=en&oi=ao" target="_blank">Mert Kilickaya</a>, 
        <a href="https://scholar.google.com/citations?user=Gsw2iUEAAAAJ&hl=en" target="_blank">Joost van de Weijer</a>, 
        <a href="https://scholar.google.com/citations?hl=en&user=CdpLhlgAAAAJ" target="_blank">Yuki Asano</a>
      </div>
      <div class="conference">Preprint 2023</div>
      <div class="links">
        <a href="https://arxiv.org/pdf/2302.00353.pdf" target="_blank">arXiv</a>
        <a href="resume/survey.pdf" target="_blank">Slides</a>
        <a href="https://github.com/kilickaya/label-efficient-il" target="_blank">GitHub</a>
      </div>
      <p>We survey semi-, few-shot, and self-supervised incremental learning.</p>
    </div>
  </div>

  <div class="research-card">
    <img src="images/VINIL.PNG" alt="Are Labels Needed for Incremental Instance Learning?">
    <div class="research-details">
      <div class="title">Are Labels Needed for Incremental Instance Learning?</div>
      <div class="authors">
        <a href="https://scholar.google.com/citations?user=MBMjO0sAAAAJ&hl=en&oi=ao" target="_blank">Mert Kilickaya</a>, 
        <a href="https://scholar.google.com/citations?user=HhDsD9UAAAAJ&hl=en" target="_blank">Joaquin Vanschoren</a>
      </div>
      <div class="conference">CVPRW 2023 (<a href="https://sites.google.com/view/clvision2023" target="_blank">Oral</a>)</div>
      <div class="links">
        <a href="https://arxiv.org/pdf/2301.11417.pdf" target="_blank">arXiv</a>
        <a href="resume/slides_vinil.pdf" target="_blank">Slides</a>
      </div>
      <p>We introduce VINIL, a self-supervised incremental instance learner.</p>
    </div>
  </div>

  <div class="research-card">
    <img src="images/BMVC21.png" alt="Human-Object Interaction Detection via Weak Supervision">
    <div class="research-details">
      <div class="title">Human-Object Interaction Detection via Weak Supervision</div>
      <div class="authors">
        <a href="https://scholar.google.com/citations?user=MBMjO0sAAAAJ&hl=en&oi=ao" target="_blank">Mert Kilickaya</a>, 
        <a href="https://scholar.google.nl/citations?user=aa5Ou7gAAAAJ&hl=en" target="_blank">Arnold Smeulders</a>
      </div>
      <div class="conference">BMVC 2021</div>
      <div class="links">
        <a href="https://arxiv.org/pdf/2112.00492.pdf" target="_blank">arXiv</a>
        <a href="resume/slides_bmvc21.pdf" target="_blank">Slides</a>
      </div>
      <p>We introduce Align-Former to detect human-object interactions from an image.</p>
    </div>
  </div>

  <div class="research-card">
    <img src="images/WACV21.png" alt="Structured Visual Search via Composition-aware Learning">
    <div class="research-details">
      <div class="title">Structured Visual Search via Composition-aware Learning</div>
      <div class="authors">
        <a href="https://scholar.google.com/citations?user=MBMjO0sAAAAJ&hl=en&oi=ao" target="_blank">Mert Kilickaya</a>, 
        <a href="https://scholar.google.nl/citations?user=aa5Ou7gAAAAJ&hl=en" target="_blank">Arnold Smeulders</a>
      </div>
      <div class="conference">WACV 2021</div>
      <div class="links">
        <a href="https://openaccess.thecvf.com/content/WACV2021/papers/Kilickaya_Structured_Visual_Search_via_Composition-Aware_Learning_WACV_2021_paper.pdf" target="_blank">arXiv</a>
        <a href="resume/slides_wacv21.pdf" target="_blank">Slides</a>
      </div>
      <p>We introduce composition-aware learning to improve visual image search.</p>
    </div>
  </div>

  <div class="research-card">
    <img src="images/EACL17.png" alt="Re-evaluating Automatic Metrics for Image Captioning">
    <div class="research-details">
      <div class="title">Re-evaluating Automatic Metrics for Image Captioning</div>
      <div class="authors">
        <a href="https://scholar.google.com/citations?user=MBMjO0sAAAAJ&hl=en&oi=ao" target="_blank">Mert Kilickaya</a>, 
        <a href="https://scholar.google.com/citations?user=-xA1_OAAAAAJ&hl=en" target="_blank">Aykut Erdem</a>, 
        <a href="https://scholar.google.com/citations?user=gwLessAAAAAJ&hl=en" target="_blank">Nazli Ikizler-Cinbis</a>, 
        <a href="https://scholar.google.com/citations?user=eALwl74AAAAJ&hl=en" target="_blank">Erkut Erdem</a>
      </div>
      <div class="conference">EACL 2017</div>
      <div class="links">
        <a href="https://arxiv.org/pdf/1612.07600.pdf" target="_blank">arXiv</a>
        <a href="resume/slides_eacl17.pdf" target="_blank">Slides</a>
      </div>
      <p>We propose Word-Mover Distance to evaluate image captioning.</p>
    </div>
  </div>
  

  <!-- Repeat for other research items -->
</section>


<style>
  .patents-section {
    background-color: #f9f9f9;
    padding: 40px 20px;
    margin: 0 auto;
    max-width: 900px;
    border-radius: 8px;
    box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
  }

  .patents-section h2 {
    text-align: center;
    margin-bottom: 30px;
    font-size: 1.8rem;
    color: #333;
  }

  .patent-card {
    background: #fff;
    padding: 20px;
    margin-bottom: 20px;
    border-radius: 8px;
    box-shadow: 0 1px 3px rgba(0, 0, 0, 0.1);
  }

  .patent-card h3 {
    font-size: 1.2rem;
    font-weight: bold;
    margin: 0 0 5px;
    color: #0066cc;
  }

  .patent-card p {
    margin: 5px 0;
    font-size: 1rem;
    color: #555;
  }

  .patent-card a {
    color: #0066cc;
    text-decoration: none;
    font-size: 0.9rem;
  }

  .patent-card a:hover {
    text-decoration: underline;
  }

  @media (max-width: 600px) {
    .patent-card {
      padding: 15px;
    }

    .patent-card h3 {
      font-size: 1.1rem;
    }

    .patent-card p {
      font-size: 0.9rem;
    }
  }
</style>

<section id="patents" class="patents-section">
  <h2>Patents</h2>

  <div class="patent-card">
    <h3>Visual Image Search via Conversational Interaction (Huawei)</h3>
    <p>Mert Kilickaya, Baiqiang XIA</p>
    <p><a href="https://patents.google.com/patent/WO2023117041A1/" target="_blank">WO Patent, 2022</a></p>
  </div>

  <div class="patent-card">
    <h3>Network for Interacted Object Localization (Qualcomm)</h3>
    <p>Mert Kilickaya, Arnold Smeulders</p>
    <p><a href="https://patents.google.com/patent/US20220414371A1/" target="_blank">US Patent, 2022</a></p>
  </div>

  <div class="patent-card">
    <h3>Subject-Object Interaction Recognition Model (Qualcomm)</h3>
    <p>Mert Kilickaya, Stratis Gavves, Arnold Smeulders</p>
    <p><a href="https://patents.google.com/patent/US11481576B2/" target="_blank">US Patent, 2022</a></p>
  </div>

  <div class="patent-card">
    <h3>Context-driven Learning of Human-object Interactions (Qualcomm)</h3>
    <p>Mert Kilickaya, Noureldien Hussein, Stratis Gavves, Arnold Smeulders</p>
    <p><a href="https://patents.google.com/patent/EP4058930A1/" target="_blank">US Patent, 2021</a></p>
  </div>
</section>



<style>
  .supervision-section {
    background-color: #f9f9f9;
    padding: 40px 20px;
    margin: 0 auto;
    max-width: 900px;
    border-radius: 8px;
    box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
  }

  .supervision-section h2 {
    text-align: center;
    margin-bottom: 20px;
    font-size: 1.8rem;
    color: #333;
  }

  .supervision-section p {
    text-align: center;
    margin-bottom: 30px;
    color: #555;
  }

  .student-card {
    display: flex;
    align-items: center;
    background: #fff;
    margin-bottom: 20px;
    padding: 15px;
    border-radius: 8px;
    box-shadow: 0 1px 3px rgba(0, 0, 0, 0.1);
  }

  .student-card img {
    width: 60px;
    height: 60px;
    border-radius: 50%;
    margin-right: 15px;
  }

  .student-details {
    flex: 1;
  }

  .student-details .name {
    font-size: 1.2rem;
    font-weight: bold;
    color: #0066cc;
    margin-bottom: 5px;
  }

  .student-details .duration {
    font-size: 0.9rem;
    color: #555;
    margin-bottom: 5px;
  }

  .student-details .project a {
    color: #0066cc;
    text-decoration: none;
    font-size: 0.9rem;
  }

  .student-details .project a:hover {
    text-decoration: underline;
  }

  @media (max-width: 600px) {
    .student-card {
      flex-direction: column;
      align-items: flex-start;
    }

    .student-card img {
      margin-bottom: 10px;
    }
  }
</style>

<section id="supervision" class="supervision-section">
  <h2>Supervision</h2>
  <p>I am very fortunate to have crossed paths with these talented individuals.</p>

  <div class="student-card">
    <img src="images/evangelos.jpg" alt="Evangelos Tsimpouris">
    <div class="student-details">
      <div class="name">
        <a href="https://www.linkedin.com/in/evangelos-tsimpouris-141a75190/?originalSubdomain=nl" target="_blank">Evangelos Tsimpouris</a> (MSc, TU/e)
      </div>
      <div class="duration">2023-2024</div>
      <div class="project">
        <a href="https://www.linkedin.com/in/evangelos-tsimpouris-141a75190/?originalSubdomain=nl" target="_blank">Learning to Transfer for Continual Learning</a>
      </div>
    </div>
  </div>

  <div class="student-card">
    <img src="images/fangqin.jpg" alt="Fangqin Zhou">
    <div class="student-details">
      <div class="name">
        <a href="https://research.tue.nl/en/persons/fangqin-zhou" target="_blank">Fangqin Zhou</a> (PhD, TU/e)
      </div>
      <div class="duration">2022-2024</div>
      <div class="project">
        <a href="https://arxiv.org/abs/2309.01561v1" target="_blank">Locality-Aware Vision Transformers</a>
      </div>
    </div>
  </div>

  <div class="student-card">
    <img src="images/ran.jpg" alt="Ran Piao">
    <div class="student-details">
      <div class="name">
        <a href="https://www.linkedin.com/in/ran-piao-a0a1a6281/?originalSubdomain=nl" target="_blank">Ran Piao</a> (MSc, TU/e)
      </div>
      <div class="duration">2022-2023</div>
      <div class="project">
        <a href="https://drive.google.com/file/d/10ntRevPI_mF00oRE9_LhQrNr09hnHNuC/view" target="_blank">Rapid Transformer Architecture Search without Training</a>
      </div>
    </div>
  </div>

  <div class="student-card">
    <img src="images/tommie.jpg" alt="Tommie Kerssies">
    <div class="student-details">
      <div class="name">
        <a href="https://scholar.google.com/citations?user=rrJn-eEAAAAJ&hl=en" target="_blank">Tommie Kerssies</a> (MSc, TU/e)
      </div>
      <div class="duration">2022-2023</div>
      <div class="project">
        <a href="https://arxiv.org/pdf/2208.08767.pdf" target="_blank">Test Time Adaptation</a>
      </div>
    </div>
  </div>
  
  <div class="student-card">
    <img src="images/ceren.jpg" alt="Ceren Gok-Yildirim">
    <div class="student-details">
      <div class="name">
        <a href="https://research.tue.nl/en/persons/ceren-g%C3%B6k" target="_blank">Ceren Gok-Yildirim</a> (PhD, TU/e)
      </div>
      <div class="duration">2022-2023</div>
      <div class="project">
        <a href="https://arxiv.org/pdf/2303.13113.pdf" target="_blank">Learning to Adapt for Continual Learning</a>
      </div>
    </div>
  </div>
  
  <div class="student-card">
    <img src="images/kishan.jpg" alt="Kishan Parshotam">
    <div class="student-details">
      <div class="name">
        <a href="https://scholar.google.com/citations?user=75hA5MQAAAAJ&hl=en" target="_blank">Kishan Parshotam</a> (MSc, UvA)
      </div>
      <div class="duration">2020-2021</div>
      <div class="project">
        <a href="https://openaccess.thecvf.com/content_CVPRW_2020/papers/w15/Parshotam_Continual_Learning_of_Object_Instances_CVPRW_2020_paper.pdf" target="_blank">Continual Learning of Object Instances</a>
      </div>
    </div>
  </div>
  
  <div class="student-card">
    <img src="images/tarun.jpg" alt="Tarun Krishna">
    <div class="student-details">
      <div class="name">
        <a href="https://krishnatarun.github.io/" target="_blank">Tarun Krishna</a> (MSc, UvA)
      </div>
      <div class="duration">2019-2020</div>
      <div class="project">
        <a href="https://drive.google.com/file/d/1klDGsZJFHzIJ1v2yQc-pCVPJESA-Rl8p/view" target="_blank">Learning to rotate, scale and shift visual objects via disentanglement</a>
      </div>
    </div>
  </div>
  
  <!-- Repeat for other students -->
</section>
